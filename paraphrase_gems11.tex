%
% Adapted from File acl-hlt2011.tex
%
% Contact: gdzhou@suda.edu.cn
%%
%% Based on the style files for ACL2008 by Joakim Nivre and Noah Smith
%% and that of ACL2010 by Jing-Shin Chang and Philipp Koehn


\documentclass[11pt]{article}
\usepackage{acl-hlt2011}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\usepackage{graphicx}
%\DeclareMathOperator*{\argmax}{arg\,max}
%\setlength\titlebox{6.5cm}    % Expanding the titlebox
\setlength\titlebox{3.5cm}    % Expanding the titlebox

\newcommand{\mnote}[1]{\marginpar{\raggedleft\footnotesize\itshape#1}} 

\title{Paraphrase Acquisition Combining Monolingual and Bilingual Information}

%\author{First Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\\And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
This paper improves an existing bilingual paraphrase extraction technique using monolingual distributional similarity to re-rank candidate paraphrases.  Raw monolingual data  provides a complementary and orthogonal source of information that lessens the commonly observed errors in bilingual pivot-based methods. We incorporated a newly developed locality sensitive hashing algorithm into the monolingual score calculation in order to facilitate a practical implementation of this method over large volumes of data. Experimental study reveals that monolingual scoring of bilingually extracted paraphrases has a significantly stronger correlation with human judgment in grammaticality than the probabilities assigned by the bilingual pivoting method.

%This shows promises in further improvement of paraphrase quality through merging of the variety of scores...@@

\end{abstract} 


\section{Introduction}
%\mnote{add back some details that were omitted due to acl short ppr constaint?}
Paraphrases are the rewording of a phrase in which the meaning is preserved. Data-driven paraphrase acquisition techniques can be categorized by the type of data that they use \cite{MadnaniDorr10}.  Monolingual paraphrasing techniques cluster phrases through statistical characteristics such as dependency path similarities or distributional co-occurrence information \cite{Lin01discoveryof,PascaDienes05}.   Bilingual paraphrasing techniques use parallel corpora extract potential paraphrases by grouping English phrases that share the same foreign translations \cite{BannardCallisonBurch05}.  Other efforts blur the lines between the two, applying techniques from statistical machine translation to monolingual data or extracting paraphrases from multiple English translations of the same foreign text \cite{Barzilay2001,PangEtAl03,QuirkDolanBrockett04}.

%Although the knowledge used by monolingual and bilingual paraphrasing techniques is largely orthogonal, only limited effort has been devoted to merging the two lines of work to develop new methodologies and applications. For instance, word-alignment from parallel monolingual data was used to train a phrasal ``translation" model \cite{QuirkDolanBrockett04}; paraphrases extracted from output of SMT trained on bilingual text are incorporated into query expansion for answer retrieval \cite{RiezlerEtAl07}.

%@@ include additional applications?@@
%Additional application of paraphrases in the domain of natural language processing includes text summarization (McKeown et al., 2002), headline or title generation (Dorr et al., 2003; Vandeghinste and Pan, 2004; Marsi et al., 2009,),  Recently paraphrase models has also been considered for sentence compression (?courtney's). An extensive survey of paraphrase methods is contained in \newcite{MadnaniDorr10}.

We exploit both types of data, applying a monolingually-derived similarity metric to the output of the pivot-based bilingual paraphrase model.  In this paper we:
\begin{itemize}
\item Show that monolingual cosine similarity calculated on large volumes texts ranks bilingually extracted paraphrases better than the paraphrase probability originally defined by \newcite{BannardCallisonBurch05} in terms of grammaticality judgment.
\item Demonstrate that monolingual distributional similarity can be implemented by Locality Sensitive Hashing, a computationally efficient approximation algorithm that has recently been extended to online signature generation \cite{Charikar02,VanDurmeLallACL10}
\item Investigate and identify the strength and weaknesses of each method in order to combine the paraphrase ranking metrics in the future.
\mnote{Something else?}
\end{itemize}
% Our work overlaps with their approach in the paraphrase generation with bilingual translation rules. However, instead of assigning paraphrase score based on phrase translation probabilities, we introduced a measure dependent on monolingual distributional similarity built upon large n-gram corpus. Locality sensitive hashing method of \newcite{Charikar02}, which has been recently extended to online signature generation by \newcite{VanDurmeLallACL10}, was implemented to enable faster computation by reducing the similarity feature space dimension with random projection. Descriptions on each stage of the process will be covered in the following sections, which are followed by examples and evaluation results.

%@@ previous work on paraphrasing reranking (monolingual and bilingual based?) @@


%\section{Related Work}
%@@ previous work on paraphrasing (monolingual and bilingual based); @@
%One example is the work on discovery of inference rule, analogous to paraphrasing, with parsed dependency trees  
%@@ Nitin Madnani's survey ppr on data driven paraphrase methods@@
%


%\section{Multilingual Paraphrase Extraction via Pivoting}
\section{Related Work}

 \newcite{BannardCallisonBurch05} proposed identifying paraphrases by pivoting through phrases in a bilingual parallel corpora. 
Figure~\ref{paraphrase-illustration} illustrates their paraphrase extraction process. A phrase to be paraphrased, like {\it thrown into jail}, is found in a German-English parallel corpus.  The corresponding foreign phrase ({\it festgenommen}) is identified using word alignment and phrase extraction techniques from phrase-based statistical machine translation \cite{KoehnEtAl03}.  Other occurrences of the foreign phrase in the parallel corpus may align to another English phrases like {\it jailed}.  (similar to SAMT formalism developed by \newcite{ZollmannVenygopal06} )%Following \newcite{BannardCallisonBurch05}, we treated any English phrases that share a common foreign phrase as potential paraphrases of each other.
%
As the original phrase occurs several times and aligns with many different foreign phrases, each of these may align to a variety of other English paraphrases.  Thus, {\it thrown into jail} not only paraphrases as {\it jailed}, but also as {\it arrested}, {\it detained}, {\it imprisoned}, {\it incarcerated}, {\it locked up}, and so on.
%{\it taken into custody}, and {\it thrown into prison} and others like {\it be thrown in prison}, {\it been thrown into jail}, {\it being arrested}, {\it in jail}, {\it in prison}, {\it put in prison for}, {\it were thrown into jail}, and {\it who are held in detention}. 
Bad paraphrases, such as
 {\it maltreated}, {\it thrown}, {\it cases}, {\it custody}, {\it arrest}, and {\it protection}, may also arise due to poor word alignment quality and other factors.

\newcite{BannardCallisonBurch05} defined a paraphrase probability to rank these paraphrase candidates,  as follows:
\begin{eqnarray} \label{paraphrase-prob-1}
 \hat{e_2}	& = & \arg \max_{e_2 \neq e_1} p(e_2 | e_1)\label{paraphrase-prob}  \\
  p(e_2|e_1) &=& \sum_f p(e_2,f|e_1)\\
                  &=& \sum_f p(e_2|f,e_1) p(f|e_1) \\
                  &\approx& \sum_f p(e_2|f) p(f|e_1)
\label{paraphrase_prob_eqn}
\end{eqnarray}
where ${p(e_2|e_1)}$ is the paraphrase probability, ${p(e|f)}$ and ${p(f|e)}$ are the translation probabilities from a statistical translation model.  

Anecdotally, this paraphrase probability sometimes seems unable to discriminate between good and bad paraphrases, so some researchers disregard it and treat the extracted paraphrases as an unsorted set \cite{Snover2010}.  \newcite{CallisonBurch08} attempts to improve the ranking by limiting paraphrases to be the same syntactic type.  

We attempt to re-rank the paraphrases using other information. This is similar to the efforts of \newcite{ZhaoEtAlACL08}, who made use of multiple resources %, namely the thesaurus, monolingual parallel corpus, monolingual comparable corpus, bilingual phrase table, dictionary definitions, clusters of similar user queries, and self paraphrase 
to derive feature functions and extract paraphrase tables. The paraphrase that maximizes the log-linear function, consisting of the feature functions and language model feature, is then selected as the optimal paraphrase. Feature weights in the model are optimized by minimizing the phrase substitution error rate, a measure proposed by the authors, on the development set using gradient descent. In our work, we examine how bilingual and monolingual re-ranking metrics complement each other in order to effectively combine them.


\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{pivot-2}
\end{center}
\caption{\small Using a bilingual parallel corpus to extract paraphrases.}
\label{paraphrase-illustration}
\end{figure}

%\section{Confidence Measure based on Monolingual Distributional Similarity}
\section{Using Monolingual Resources}
\label{sect:mds}

Prior work has explored the acquisition of paraphrases using distributional similarity computed from monolingual resources, such as in the DIRT results of \newcite{Lin01discoveryof}. Later work by \newcite{BhagatRavichandran08}, building on an earlier effort in noun clustering \cite{ravichandranACL05}, leveraged the Locality Sensitive Hash (LSH) results of \newcite{Charikar02} and \newcite{IndykSTOC98} in order to scale the acquisition model to large datasets.

In these models, phrases are judged to be similar based on the cosine distance of their associated context vectors. In some cases, such as by Lin and Pantel, distributional context is defined as the frequency within which a given element appears in various syntactic positions with respect to other lexical items.\footnote{For example, the nouns \emph{apple} and \emph{orange} are contextually similar partly owing to their shared tendency to be the object of the verb \emph{eat}.} While syntactic contexts provide strong evidence of distributional preferences, they are relatively computationally expensive to come by, prompting the use instead of n-gram features when employing very large corpora (such as in the work of Bhagat and Ravichandran).\footnote{For example, \emph{apple} and \emph{orange} both tend to be one word to the right of \emph{an}, and one to the left of \emph{juice}.}

Here we derived distributional similarity through the use of the Google n-grams \cite{GoogleNgrams}. Given both the size of the collection, and that the n-grams are sub-sentential (the n-grams are no longer than 5 tokens by design), it was not feasible to parse, which led to the use of unigram contexts. For each phrase $x$ we wished to paraphrase, we extracted the context vector of $x$ from the n-gram collection as such: every (n-gram, frequency) pair of the form: ($a x$, $f$), or ($x b$, $f$), gave rise to the (feature, value) pair: ($w_{i-1}=a, f$), or ($w_{i+1}=b, f$), respectively. In order to avoid storing each context vector explicitly, and to enable faster cosine comparisons, we employed the online LSH approach of \newcite{VanDurmeLallACL10}.


%\section{Dimensionality Reduction via LSH}
%\label{sect:lsh}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}
We evaluate the paraphrase confidence metrics by first demonstrating some paraphrase examples from a small preliminary study on bilingual pivoting paraphrase extraction and re-ranking methods. Next, we present the results from an experimental study, pivoting over a large French-English corpus, to qualitatively evaluate the correlation between each paraphrase scoring method and human judgments in terms of paraphrase grammaticality and meaning-preservation. %A more systematic analysis will then be presented in Section \ref{results_fr_en} through another experimental study  demonstrating the strengths and weaknesses of each method. 

For presentation simplicity, monolingual distributional similarity via LSH, bilingual pivoting and syntactically-constrained bilingual pivoting are labeled throughout as MonoDS, BiP and SyntBiP, respectively. In terms of paraphrase extraction methods, bilingual pivoting (BiP) and syntactically-constrained bilingual pivoting (SyntBiP) re-ranking methods are assumed to operate on paraphrases extracted from the respective paraphrasing methods. For the monolingual distributional similarity (MonoDS) scores, the paraphrase extraction method is indicated by the prefix of the label, for example, BiP-MonoDS. Note that for Section \ref{sect:results_fr_en}, an additional re-ranking method denoted as SyntBiP$_{matched}$ is the same as SyntBiP except that only paraphrases with syntactic type matching that of the original phrase in a given sentence are included in the correlation calculation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data}

In the preliminary study, a bilingual paraphrase model was trained using the parallel corpus between Urdu and English from NIST 2009. This data set, which was collected from newswire and weblogs, consists of roughly 1.7 million words and 200K sentences in each language. The word alignments in this parallel corpus were generated with the Berkeley aligner and the English dataset was parsed using Stanford parser \cite{KleinManning03}. %\newcite{VanDurmeLallNIPS09}%VanDurmeLallACL10} \cite{}

For the experimental study in which human judgment was collected from the Mechanical Turk, the French-English parallel text from the Europarl corpus \cite{Koehn05} was used to train the paraphrase model. The parallel corpus was extracted from proceedings of the European parliament with a total of over 1 million sentences and close to 100 million words in the English text. The rest of grammar extraction preprocessing follows the same procedure for the Urdu-English data. This bilingual corpus is a much larger data set and therefore is expected to provide larger coverage and more reasonable paraphrases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Re-ranking Methods}
In both experiments, the bilingual pivoting-based paraphrase models were adopted from the bilingual pivoting-based method in \newcite{BannardCallisonBurch05}, and the syntactically-constrained bilingual pivoting in \newcite{CallisonBurch08}. For the syntactically constrained paraphrase extraction, CCG-style notation for syntactic labeling \cite{Steedman99} was incorporated in order to reinforce syntactic type matching for paraphrases in the bilingual pivoting stage. Note that grammar rules from the translation models with non-terminal labels are excluded in paraphrase pivoting.

%The Google N-gram Corpus (Brants and Franz, 2006) 
The web-scale n-gram collection of \newcite{LinEtAlLREC10} was used to compute the monolingual distributional similarity features. A random values pool size of 10000 and 512 random projection vectors (i.e. bits) per n-gram are used for the task. In order to expand the coverage of the candidates scored by the monolingual method, the LSH signatures are obtained only for the phrases in the union set of the phrase-level outputs from the original and from the syntactically constrained paraphrase models. Since the n-gram corpus consists of at most 5-gram and the each distributional similarity feature requires single neighboring token, the LSH signatures are generated only for phrases that are 4-gram or less. Phrase pairs with negative LSH scores, which indicate that the phrases are distributionally dissimilar in the feature space, are ignored in the analysis.

While the training data for the bilingual paraphrase models and the testing data for human evaluation come from the Europarl corpus in which the english structure follows the European parliament proceedings, the data for monolingual distributional similarity feature extractions comes from web-scale n-gram collection consisting of english text from diverse sources. As a result, language statistics from different data are involved in paraphrase selection based on bilingual pivoting followed by monolingual distributional similarity re-ranking.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Design}
The experiments on human evaluation of confidence measures produced by bilingual- and monolingual-based paraphrase scores were performed through human intelligence tasks (HIT) on Amazon's Mechanical Turk in the context of paraphrase substitution. For each of the 4 n-gram category, 25 phrases are randomly sampled from the paraphrase table generated by the bilingual pivoting method. A phrase is selected according to the following requirements:

\begin{itemize}
\item Phrase occurs at least 5 times in the parallel corpus and has appeared in web-scale n-gram, i.e. contains a non-zero LSH signature
\item There is at least 1 non-negative LSH score based on monolingual distributional similarity.
\item The union of paraphrase candidates from BiP, SyntBiP and MonoDS must be greater than 10.
\end{itemize}

After a phrase is chosen, the union of the top paraphrase candidates from each method are used as the final paraphrase set. Five distinct sentences for each source phrase are sampled for constructing the HIT. Each HIT contains multiple sentences, each of which contains a phrase extracted as described. For every paraphrase candidate of a particular phrase, the phrase in the sentence is substituted in by its candidate. Sentences in a HIT are presented to a human judge along with the original context. For each sentence in the HIT, the judge is asked to use a 5-point grading scale to evaluate, in isolation, the extent of meaning-preservation and grammaticality of the paraphrase replacement, with 5 being the most favorable. Human evaluation of each sentence is repeated by multiple turkers (Mechanical Turk workers) and the averaged score for each phrase-paraphrase pair is subsequently used for analysis.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluation Metric}
Evaluation on the correlation between the ranking according to each of the paraphrase scores and human judgment is based on Kendall's tau coefficient, a common measure of correlation between two ranked quantities. Given a set of elements ranked by 2 different metrics, one interpretation of Kendall's tau is the ratio of agreement in relative ranking in all possible pairs of values drawn from the set. Kendall's tau coefficient ranges between -1 and 1, where 1 indicates a perfect agreement between a pair of ranked lists. 

Kendall's tau b, a variant of Kendall's tau, accounts for tied ranking within a ranked list by simply ignoring counts of pairs with ties in the ratio. Since tied rankings sometimes occurs in human judgment results as well as all 3 re-ranking methods, Kendall's tau b is used in our analysis. An overall Kendall's tau coefficient presented in the results section is calculated by averaging all Kendall's tau coefficients of a particular re-ranking method over all phrase-sentence combinations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preliminary study on Urdu-English data}
\label{sect:results_ur_en}

A small preliminary study of the paraphrasing metrics were performed prior to the experimental work with French-English corpora. Due to the significantly smaller corpus size as compared to the one used in \newcite{CallisonBurch08}, the translation and paraphrase candidates presented here are expected of lesser quality. Nonetheless, the results in this demonstrates the flexibility of the choice of foreign language used in the bilingual pivoting paraphrase extraction.

\begin{table}[h]
\begin{center}
\begin{tabular}{ccc}%{|l|l|l|}
\hline\hline \bf \scriptsize BiP & \bf \scriptsize SyntBiP & \bf \scriptsize MonoDS \\ \hline
{\scriptsize necessary (0.118)} & {\scriptsize needlessly (0.024)} & {\scriptsize needlessly (0.93)} \\
{\scriptsize reason (0.084)} & {\scriptsize only (0.012)} & {\scriptsize groundless (0.85)} \\
{\scriptsize unnecessary (0.074)}& {\scriptsize exactly (0.003)}& {\scriptsize unnecessary (0.79)}\\
{\scriptsize same (0.050)} & {\scriptsize just (0.001)} & {\scriptsize useless (0.79)} \\
{\scriptsize useless (0.037)}& {\scriptsize always (0.001)}& {\scriptsize illegally (0.78)}\\
\hline
\end{tabular}
\end{center}
\caption{Paraphrases for {\em unnecessarily} according to the bilingual pivoting (BiP), syntactic-constrained bilingual pivoting (SyntBiP) and the monolingual distributional similarity (MonoDS) scores, ranked within each column by the scores in brackets}
\label{table1}
\end{table}

An example shown in Table~\ref{table1} consists of a list of top 5 paraphrases generated for the word  {\em unnecessarily} and the corresponding paraphrase scores from each of the 3 confidence metrics. Only {\em unnecessary} and {\em useless} from the original bilingual paraphrase extraction are semantically close to actual phrase but are different syntactically; whereas for SyntBiP, only the best paraphrase candidate, {\em needlessly}, shares close enough meaning with {\em unnecessarily}. 
The lack of semantic correspondence observed in the bilingual methods is likely due to either polysemy in the foreign translation or word alignment mismatch in the bilingual translation. Such problems are not pronounced in the monolingual-based scores. The top LSH scores are close to the maximum Kendall's tau value of 1, indicating that the corresponding paraphrases, such as {\em needlessly}, are quantitatively similar to the true phrase in terms of distributional similarity.


Table~\ref{table2} shows the paraphrase candidates and scores for the phrase {\em huge amount of}. Although MonoDS does not explicitly impose syntactic restrictions, the syntactic structure of the paraphrase {\em in large numbers} contributes to the drastically difference in the left and right context of the paraphrase and of the original phrase. Hence, the paraphrase was assigned a low score of 0.098 as compared to other paraphrase candidates with correct syntactic type. Note that the SyntBiP produced significantly less paraphrase candidates, which exemplifies the lack of coverage commonly observed in this paraphrase model as mentioned in \newcite{CallisonBurch08}. %This should be kept in mind if the number of paraphrase candidates is a concern.%Therefore, it is important to expand the paraphrases for the monolingual scoring by taking the union of candidates from both kinds of bilingual paraphrase model.

\begin{table}[t!]
\begin{center}
\begin{tabular}{ccc}%{|l|l|l|}
\hline\hline 
\bf \small BiP & \bf \small SyntBiP & \bf \small MonoDS \\ \hline
{\scriptsize large number of, 0.33} & {\scriptsize large number of, 0.38} & {\scriptsize large quantity of, 0.98} \\
{\scriptsize in large numbers, 0.11} & {\scriptsize great number of, 0.09} & {\scriptsize large number of, 0.98} \\
{\scriptsize great number of, 0.08}& {\scriptsize vast number of, 0.06}& {\scriptsize great number of, 0.97}\\
{\scriptsize large numbers of, 0.06} & & {\scriptsize vast number of, 0.94} \\
{\scriptsize vast number of, 0.06}& & {\scriptsize in large numbers, 0.10}\\
\hline
\end{tabular}
\end{center}
\caption{Paraphrases for {\em huge amount of} according to the bilingual pivoting (BiP), syntactic-constrainted bilingual pivoting (SyntBiP) translation score and the monolingual similarity score via LSH (MonoDS), ranked by corresponding scores listed next to each paraphrase}
\label{table2}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental Results}
\label{sect:results_fr_en}

Prior to performing analysis on the data collected from the experiment, preprocessing was performed for data quality control and for correct Kendall's tau calculation. A HIT is rejected if a turker fails on the control questions embedded in the HIT or if more than a pre-defined number of entries are left empty. Ranked lists produced by human judgment for a particular phrase would be tossed out if rankings are equal across all paraphrase candidates. Hence, Kendall's tau coefficients are calculated from various sizes of support, which are indicated along with the results. A total of 100 phrases and 5 sentence per phrase are selected for the experiment, resulting in a maximum support size of 500 for Kendall's tau coefficient calculation.

\begin{table}%[t!]
\begin{center}
\begin{tabular}{rcc}%{|l|l|l|}
\hline\hline \bf \footnotesize Re-ranking Method & \bf \footnotesize Meaning & \bf \footnotesize Grammar \\ \hline
{\scriptsize BiP} & {\scriptsize 0.14 (475)} & {\scriptsize 0.04 (471)} \\
{\scriptsize BiP-MonoDS} & {\scriptsize 0.14 (493)} & {\scriptsize \bf 0.24 (490)} \\
{\scriptsize SyntBiP} & {\scriptsize \bf 0.19 (300)}& {\scriptsize 0.08 (292)} \\
{\scriptsize SyntBip-MonoDS} & {\scriptsize 0.15 (326)} & {\scriptsize 0.22 (318)} \\
\hline 
{\scriptsize SyntBiP$_{matched}$} &  {\scriptsize 0.20 (179)} & {\scriptsize 0.15 (175)} \\
{\scriptsize SyntBiP$_{matched}$-MonoDS}&  {\scriptsize 0.17 (190)} & {\scriptsize 0.16 (187)} \\
{\scriptsize SyntBiP*} &  {\scriptsize \bf 0.21 (273)} & {\scriptsize 0.09 (266)} \\
{\scriptsize SyntBiP-MonoDS*}&  {\scriptsize 0.16 (295)} & {\scriptsize \bf 0.22 (288)} \\
\hline
\end{tabular}
\end{center}
\caption{Kendall Tau's rank coefficients for correlation of human judgment in terms of paraphrase meaning and grammaticality with different paraphrase scores. Bottom panel: SyntBiP$_{matched}$ is the same as SyntBiP except paraphrases must match with the original phrase in syntactic type. SyntBiP* and MonoDS* are the same as before except they share the same phrase support with SyntBiP$_{matched}$. Size of support is listed in brackets. Numbers with bolded face are the maximum values}
%\caption{Kendall Tau's rank coefficients for correlation of human judgment in terms of paraphrase meaning and grammaticality with bilingual pivoting (BiP), syntactically-constrained bilingual pivoting (SyntBiP), and monolingual distributional similarity via LSH (MonoDS) paraphrase scores. Bottom panel: SyntBiP$_{matched}$ is the same as SyntBiP except paraphrases must match with the original phrase in syntactic type. SyntBiP* and MonoDS* are the same as before except they share the same phrase support with SyntBiP$_{matched}$. Size of support is listed in brackets. Numbers with bolded face are the maximum within that column}
\label{tbl:table4} 
\end{table}
% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTau_all_sorted: all Kendal Tau scores
% cnt_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau


\mnote{grammar: MonoDS $>$ BiP in both panels} %%%
The Kendall's tau coefficients calculated using human evaluation and various paraphrase re-ranking scores are reported Table \ref{tbl:table4}. The positive values of Kendall's tau across the entire table confirm both monolingual and bilingual approaches for paraphrase re-ranking are consistent with human judgement overall. In the grammaticality category, monolingual distributional similarity re-ranking generally correlates stronger with human judgment than bilingual pivoting methods. For example, in the top panel, given a paraphrase table generated by bilingual pivoting method, Kendall's tau for monolingual distributional similarity metric (BiP-MonoDS) achieves 0.24 while that of the bilingual pivoting re-ranking (BiP) is only 0.04. Similarly, re-ranking of the paraphrases extracted with syntactically-constrained bilingual pivoting shows a stronger correlation between SyntBiP-MonoDS and human judgment (0.22) than the SyntBiP (0.08). The rest of the table suggest likewise. This result further increases the confidence of distributional similarity in paraphrase re-ranking in terms of grammaticality, which is expected because the distance between two phrases in terms of contextual distribution defines the closeness between the associated syntactic structures and grammatical fluency.

\mnote{meaning: BiP $>$ MonoDS in both panels} %%%
In terms of meaning preservation, the Kendall's tau coefficent for MonoDS is mostly lower than the bilingual approaches, suggesting that paraphrase probability from the bilingual approach correlates better with phrasal meaning than monolingual metric. For instance, SyntBiP reaches a Kendall's tau of 0.19, 0.04 higher than that of SyntBiP-MonoDS. Although paraphrase candidates were generated by bilingual pivoting, distributional similarity depends on only contextual similarity and does not guarantee paraphrase that matches with original meaning. On the contrary, bilingual pivoting metrics are derived based on likelihood the shared foreign translation which associates meaning. 

\mnote{BiP: Meaning $>$ Grammar; MonoDS: Grammar $>$ Meaning in both panels} %%%
The characteristics of each re-ranking method can be observed by comparing the coefficients within each row, which corresponds to the correlation between a particular re-ranking method to each of the meaning and grammar scores. In all of the bilingual pivoting approaches, Kendall's tau is higher in meaning preservation than grammaticality. For instance, SyntBiP has a Kendall's tau of 0.19 in meaning, 0.11 higher than that in grammaticality. Contrastingly, distributional similarity metrics correlates more with the grammaticality, except for the case of matched syntactic type, with BiP-MonoDS achieving a coefficient of 0.24 in the grammaticality but only a 0.14 in meaning. Bilingual pivoting without additional constraints is known to perform better in paraphrase extraction in meaning perservation than grammaticality \cite{BannardCallisonBurch05}, whereas with the distributional similarity groups phrases into syntactic classes with less emphasis on the similarity of their actual meaning.The orthogonal advantages of the re-ranking methods will be exploited to construct a more fitting paraphrase re-ranking metric.

\mnote{BiP, Meaning: SyntBiP $>$ BiP; Grammar: SyntBiPmatched $>$ SyntBiP} %%%
In the bottom panel of Table \ref{tbl:table4}, only paraphrases of the same syntactic type as the source phrase are included in the ranked list for Kendall's tau calculation. The phrases associated with these paraphrases are used for calculating Kendall's tau for the original re-ranking methods (labeled as SyntBiP* and SyntBiP-MonoDS*). Comparing only the bilingual methods across panels, syntactic matching definitely increases the correlation of bilingual pivoting metrics with human judgments in grammaticality (e.g. 0.15 for SyntBiP$_{matched}$ and 0.08 for SyntBiP) but with only minimal effects on meaning. The maximum values in the bottom panel for both categories are roughly the same as that in the corresponding category in the upper panel (\{0.21,0.19\} in meaning and \{0.22, 0.24\} in grammar for lower and upper panels, respectively.) This suggests that syntactic type matching offers only minor advantage when distributional similarity metric is used in conjunction with the bilingual approach, although it definitely help in grammaticality within purely bilingual pivoting re-ranking.

It should not be surprising that most of the re-ranking metric correlates less with meaning than grammar judgment because grammaticality is fairly rigidly defined whereas meaning is a subjective measure that varies among individuals and depending on sentence context. As such, human judgement scores on meaning are subjected to more noise and inconsistency, which indirectly contribute to lower Kendall's tau coefficients.



%%%%%%%%% table for pphrase size analysis, at MOST size N
\begin{table}%[t!]
\begin{center}
\begin{tabular}{rcccc}%{|l|l|l|}
\hline \hline 
%\bf \scriptsize Re-ranking & \multicolumn{3}{c} {@3} &  \multicolumn{3}{c}{@6} &  \multicolumn{3}{c}{@10} &  \multicolumn{3}{c}{@15} &  \multicolumn{3}{c}{@20} &  \multicolumn{3}{c}{@30} \\
 & \multicolumn{2}{c} {\scriptsize BiP} &  \multicolumn{2}{c}{\scriptsize BiP-MonoDS} \\
\bf \scriptsize $\leq$ N$_{pool}$ & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G \\ \hline
{\scriptsize 3} & {\scriptsize 0.24 (36)} & {\scriptsize 0.30 (33)} & {\scriptsize 0.30 (49)} & {\scriptsize 0.21 (47)} \\
{\scriptsize 6} & {\scriptsize 0.16 (90)} & {\scriptsize 0.27 (86)} & {\scriptsize 0.26 (108)} & {\scriptsize 0.25 (105)} \\
{\scriptsize 10} & {\scriptsize 0.16 (150)} & {\scriptsize 0.22 (146)} & {\scriptsize 0.24 (168)} & {\scriptsize 0.27 (165)} \\
{\scriptsize 15} & {\scriptsize 0.13 (195)} & {\scriptsize 0.18 (191)} & {\scriptsize 0.21(213)} & {\scriptsize 0.28 (210)} \\
{\scriptsize 20} & {\scriptsize 0.12 (280)} & {\scriptsize 0.12 (276)} & {\scriptsize 0.18 (298)} & {\scriptsize 0.26 (295)} \\
{\scriptsize 30} & {\scriptsize 0.13 (375)} & {\scriptsize 0.07 (371)} & {\scriptsize 0.16 (393)} & {\scriptsize 0.25 (390)} \\

\hline
\end{tabular}
\end{center}
\caption{Kendall's tau rank coefficients for correlation between human judgment and 2 re-ranking methods as a function of the maximum size of paraphrase candidate pool. Support is indicated in the bracket; meaning and grammar are represented as M and G, respectively}
\label{table7} 
\end{table}
% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauPPsize_all_sorted: all Kendal Tau scores
% cntPPsize_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau

% not related to table7
A similar analysis was performed by breaking up phrases into n-gram categories and the result, which is not included here, was similar to the overall case where re-ranking scores based on bilingual pivoting have higher correlation in meaning and lower in grammar than those based on distributional similarity.

\mnote{effect of paraphrase candidate pool sizes} %%%
The effects from the paraphrase candidate pool sizes are illustrated in Table \ref{table7}. Both ranking metrics decrease gradually in correlation with human judgment in meaning as the number of available paraphrases grows. The same relationship occurs for BiP in the grammaticality but the Kendal's tau stays roughly the same, which implies that even at large numbers of paraphrase candidates, distributional similarity can serve as a metric   close to human judgment in ordering grammaticality.

\mnote{correlation between human judgment scores and LSH binning} %%%

%%%%%%%%% table for LSH cutoff on average meaning and grammar analysis
\begin{table}%[t!]
\begin{center}
\begin{tabular}{rcccc}%{|l|l|l|} ################################### fill in table with results avgLSHgrammar and avgLSHmeaning
\hline \hline
\bf \scriptsize LSH Region & \bf \scriptsize Meaning & \bf \scriptsize Grammar & \bf \scriptsize Support \\ \hline
%{\scriptsize 1 $\geq$ x $>$ 0.9} & {\scriptsize 3.49} & {\scriptsize 4.17} & {\scriptsize 905}  \\
%{\scriptsize 0.9 $\geq$ x $>$ 0.8} & {\scriptsize 3.27} & {\scriptsize 3.98} & {\scriptsize 830}  \\
{\scriptsize 1 $\geq$ x $>$ 0.95} & {\scriptsize 3.99} & {\scriptsize 4.43} & {\scriptsize 350}  \\
{\scriptsize 0.95 $\geq$ x $>$ 0.9} & {\scriptsize 3.17} & {\scriptsize 4.00} & {\scriptsize 555}  \\
{\scriptsize 0.9 $\geq$ x $>$ 0.85} & {\scriptsize 3.25} & {\scriptsize 3.98} & {\scriptsize 470}  \\
{\scriptsize 0.85 $\geq$ x $>$ 0.8} & {\scriptsize 3.30} & {\scriptsize 3.98} & {\scriptsize 360}  \\
{\scriptsize 0.8 $\geq$ x $>$ 0.7} & {\scriptsize 3.21} & {\scriptsize 3.91} & {\scriptsize 750}  \\
{\scriptsize 0.7 $\geq$ x $>$ 0.6} & {\scriptsize 3.27} & {\scriptsize 3.80} & {\scriptsize 935}  \\
{\scriptsize 0.6 $\geq$ x $>$ 0.5} & {\scriptsize 3.08} & {\scriptsize 3.68} & {\scriptsize 915}  \\
{\scriptsize 0.5 $\geq$ x $>$ 0.4} & {\scriptsize 3.1 } & {\scriptsize 3.57} & {\scriptsize 665}  \\
{\scriptsize 0.4 $\geq$ x $>$ 0.3} & {\scriptsize 3.08} & {\scriptsize 3.54} & {\scriptsize 790}  \\
{\scriptsize 0.3 $\geq$ x $>$ 0.2} & {\scriptsize 2.93} & {\scriptsize 3.35} & {\scriptsize 805}  \\
{\scriptsize 0.2 $\geq$ x $>$ 0.1} & {\scriptsize 2.98} & {\scriptsize 3.30} & {\scriptsize 880}  \\
{\scriptsize 0.1 $\geq$ x $>$ 0} & {\scriptsize 2.89} & {\scriptsize 3.21} & {\scriptsize 760}  \\
\hline
\end{tabular}
\end{center}
\caption{Averaged human judgment scores as a function of binned LSH scores for correlation between human judgment and monolingual distributional similarity via LSH in terms of meaning and grammar.}
\label{table9}
\end{table}
% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauLSHCutoff_all_sorted: all Kendal Tau scores
% cntLSHCutoff_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau

To verify whether scores of MonoDS via LSH correspond to human judgment of paraphrases, human evaluation scores are averaged for meaning and grammar within each range of approximate cosine distance, as shown in Table \ref{table9}. Supports are larger than 500 because different paraphrase candidates are also taken into account.

Similar to results in previous tables, scores are uniformly higher in grammar than meaning across all score bins. The averaged grammar scores decreases monotonically and proportionally to the change in LSH values, as expected from the previously discussion. With regard to meaning scores, the averaged values roughly correspond to the decrease of LSH values, implying distributional similarity correlates weakly to human judgment of the meaning preservation of paraphrase. 

Note that the drop in averaged scores is the largest from the top bin (1$\geq$ x $>$ 0.95) to the second bin (0.95 $\geq$ x $>$ 0.9) is the largest within each category. For example, in the meaning category, while the score goes from 3.99 in the first bin to 3.17 in the second bin, the rest of the bins hovers around 3.20 in the following 6 bins. Similar trend can be observed in the grammar averaged scores as well. This suggests that high confidence in meaning and grammaticality can be associated with paraphrases that achieves LSH scores of 0.95 or above.

%** top range: one bin on top way higher than the avg value in the lower bins (~3.20) = can be confident about paraphrase with above 0.95 (step function drop off after 0.05 from 1)


\mnote{on top K analysis} %%%
%@@ data is noisy (known fact from mTurk, cite), so kTau metric can be benefited if only topK candidates are used in the evaluation, however cutoff of K needs to be determined systematically/adaptively@@

% graph of average topK w.r.t. K
\begin{figure*}
\begin{center}
\includegraphics[width=0.8\linewidth]{meanTopK} %[width=\linewidth]
\end{center}
\caption{\small Mean score in the top K paraphrase candidates as a function of K for different re-ranking metrics}
\label{fig_meanTopK}
\end{figure*}

Since crowd-sourced human evaluation is known to be noisy, rather than examining the correlation using the entire ranked paraphrase lists, analyzing top K paraphrases as a function of K is another appropriate way to evaluate the goodness of different metrics. Figure \ref{fig_meanTopK} shows the mean human assigned score within the top K candidates averaged across all phrases. Due to different sizes of paraphrase pool for various phrases, the support of the averaged scores decreases from 500 to 100 as K increases. Compared across the categories, meaning scores have lower range of score and a more uniform trend of decreasing values as K grows.  In grammaticality, BiP clearly underperforms whereas the SyntBiP-MonoDS maintains the best score among all methods over all values of K. In addition, a slow dropoff up until K = 4 implies that quality of paraphrases remains relatively high going from top 1 to top 4 candidates.

\mnote{on max top K candidates}%%%
In question answering applications such as search query, the order of answers presented is important because the lower an answer is ranked, the less likely it would be looked at or chosen, or, equivalently, more time would be spent to find an optimal answer. Based on this intuition, the paraphrase ranking methods are evaluated using the maximum human judgment score among the top K candidates obtained by each method. As shown in Table \ref{table10}, when only the top candidate is considered, the averaged score corresponding to the monolingual re-ranking methods are roughly the same as that to the bilingual methods in meaning, but as K grows, the bilingual methods outperforms the monolingual methods. In terms of grammaticality, scores associated with monolingual re-ranking methods are consistently higher than the bilingual methods but the difference tapers off as K increases. This suggests that when only limited top paraphrase candidates can be evaluated, MonoDS should guarantee better quality of results.


%%%%%%%%%%%%% Average of **max** of Top K meaning and grammar for each re-ranking score 
\begin{table}%[t!]
\begin{center}
\begin{tabular}{ccc p{10mm} cp{10mm}}%{|l|l|l|}
%{@{\extracolsep{\fill}}ccccccc}
\hline \hline & &  \multicolumn{4}{c} {\bf \scriptsize Re-ranking Method} \\
& {\bf \scriptsize K} & {\scriptsize BiP} & {\scriptsize BiP-MonoDS} & {\scriptsize SyntBiP} & {\scriptsize SyntBiP-MonoDS} \\
\hline
\multirow{4}{*}{\scriptsize M} &{\scriptsize 1} & {\scriptsize 3.62 } & \multicolumn{1}{c}{\scriptsize 3.67} & {\scriptsize 3.58} & {\scriptsize 3.58}\\
&{\scriptsize 3} & {\scriptsize 4.13}  & \multicolumn{1}{c} {\scriptsize 4.07} & {\scriptsize 4.13} & {\scriptsize 4.01}\\
&{\scriptsize 5} & {\scriptsize 4.26}   & \multicolumn{1}{c} {\scriptsize 4.19}  & {\scriptsize 4.20}  & {\scriptsize 4.09}\\
&{\scriptsize 10} & {\scriptsize 4.39}   & \multicolumn{1}{c} {\scriptsize 4.30} & {\scriptsize 4.25} & {\scriptsize 4.23} \\
\hline
\multirow{4}{*} {\scriptsize G} & \bf \scriptsize 1  & {\scriptsize 3.83} & \multicolumn{1}{c} {\scriptsize 4.11} & {\scriptsize 4.04}  & {\scriptsize 4.23}\\
&{\scriptsize 3} & {\scriptsize 4.22} & \multicolumn{1}{c} {\scriptsize 4.45}  & {\scriptsize 4.47} & {\scriptsize 4.54}\\
&{\scriptsize 5}  & {\scriptsize 4.38} & \multicolumn{1}{c} {\scriptsize 4.54}& {\scriptsize 4.55}  & {\scriptsize 4.62} \\
&{\scriptsize 10} & {\scriptsize 4.52} & \multicolumn{1}{c} {\scriptsize 4.62} & {\scriptsize 4.63} & {\scriptsize 4.67} \\
\hline
\end{tabular}
\end{center}
\caption{Average of the maximum human evaluation score from top K candidates for each re-ranking method, where the size of support for BiP and BiP-MonoDS is 500, for SyntBiP and SyntBiP-MonoDS is 335. (M = Meaning, G = Grammar) }
\label{table10} 
\end{table}
% variable avgTopK in code, e.g. avgTopK[kTop]['meaning']['hiero']




% @@ examples of LSH better than BiP @@
\mnote{example of misalignment: 3 examples} %%%
%- considerable changes    1069038 caused quite    1.0     1.0     21.5    1.0  (m:23)
%- always declared 377087  always been     1.0     1.0     19.0    8.0 (m:20)
%- significantly affected  10321   known   2.0     2.5     20.0    4.0 	(max 20)
%@@ example for which LSH helping out Multilingual Pivoting when misalignment is severe (non-sense paraphrases) (1) cite ccb's ppr and mention well-known fact about aligner quality and direct deterioration propagation in pivoting-based (or any grammar-extraction-based method) paraphrase extraction and (2) *briefly* mention potentially incorporating of LSH and tomb counter in improving misalignments, for example, by counting whether aligned phrases co-occur frequent enough in corpus) @@
The examples in the top panel of Table \ref{table11} illustrates a few disadvantages of the bilingual paraphrase scores and how monolingual re-ranking complements the bilingual methods. Translation models based on bilingual corpora is known to suffer from misalignment of the parallel text \cite{BannardCallisonBurch05}, producing incorrect translations that propagate through in the paraphrase model. This issue is exemplified in the phrase pairs \{\emph{considerable changes, caused quite}\}, \{\emph{always declared, always been}\}, and \{\emph{significantly affected, known}\} listed Table \ref{table11}. The paraphrases are clearly unrelated to the corresponding phrases as evident from the low rankings from human judges. Nonetheless, they were included as candidates likely due to misalignment and were ranked relatively high by BiP metric. Note that in these cases LSH produces results that agrees with the meaning and grammar rankings.

\mnote{example of LSH helping grammaticality}
% of the size     186649  the size of the 9.0     3.0     14.0    5.0 (m:19)
The phrase pair \{\emph{of the size, the size of the}\} may appear in similar context in the training corpora, therefore a rank of 6 out of 19 was assigned by the bilingual metric. However, the actual context of what follows each of the phrases are different by construct, i.e. a quantitative measure and an object should follow the phrases \emph{of the size} and \emph{the size of the}, respectively. For example, one of the sentences goes as follow:

\hangindent=\parindent{\textit{...which fall victim to harassment , from women and the disabled to foreigners and people of a different faith . this gives us an idea \textbf{of the size} of the problem .}}

As such, the paraphrase was ranked 11 and 17 out of 18 by human judges. The clear difference between neighbor content for each of the phrases helps LSH metric to give a low ranking of 15, demonstrating the cue of neighboring content defined by a phrase can be partially accounted for by distributional similarity.

%\emph{we need to encourage innovation in all possible fields , we need to base our economy on knowledge and education and we need to foster entrepreneurship , irrespective \textbf{of the size} of the companies in question .}

\mnote{effect by context} %%%
% hauled  344042  delivered       17.0    18.5    2.5     19.0
Occasionally, the paraphrase are context-based, meaning relevant of paraphrase depends on the context in a sentence. Bilingual method can capture limited context through syntactic constraints if the POS tags of the paraphrases and the sentence are available, while distributional similarity metric, in its current implementation, is purely based on the pattern of co-occurrence with neighboring context. As a result, LSH score should be slightly better at gauging the paraphrases defined by context, as suggested by some examples in Table \ref{table11}. The phrase pair \{\emph{hauled, delivered}\} differ slightly in how they describe the manner an object is displaced. However, in the context of the following sentence, they roughly correspond to the same idea:

\hangindent=\parindent{\textit{countries which do not comply with community legislation should be \textbf{hauled} before the court of justice and i think mrs palacio will do so .}

As a result, out of 23 candidates, human judges ranked \emph{delivered} 7 and 5.5 for meaning and grammar, respectively. Monolingual-based metric also assigns a higher rank to the paraphrase while BiP puts it near the lowest rank.

\mnote{effect by context} %%%
Another example of context-dependency is the phrase pair \{\emph{fiscal burden, taxes}\}, which could have some foreign translations in common. The original phrase appears in the following sentence:

\hangindent=\parindent{\textit{... so that small and medium-sized enterprises can benefit from research investment and the member states can reduce the \textbf{fiscal burden} consisting of taxes and social contributions .}}

The paraphrase candidate \emph{taxes} no longer appropriate with the consideration of the context surrounding the original phrase. As such,  \emph{taxes} received rankings of 13.5, 18 and 16 out of 18 for meaning, grammar, and MonoDS, respectively, whereas BiP assigns a 6 to the paraphrase. On the contrary, with the same phrase pair but a different sentence, the contextinduces oppose effects on the paraphrase judgments, where the paraphrase received 2 and 8 in the two categories as shown in Table \ref{table11}:

\hangindent=\parindent{\textit{the economic data for our eu as regards employment and economic growth are not particularly good , and , in addition , the \textbf{fiscal burden} in europe , which is to be borne by the citizen , has reached an all-time high of 46 \% . }

Hence, distributional similarity offers additional advantages over BiP only when paraphrase appears in context that also defines most of the non-zero dimensions of the LSH signature vector.

\mnote{effect of training MonoDS and BiP with different corpora}
An example to illustrate the effect of using different corpora to train the 2 paraphrase re-ranking models is the phrase pair \{\emph{legalise}, \emph{legalize}\}, as shown in Table \ref{table11}. Meaning, grammar and MonoDS all received top rank out of all paraphrases, whereas BiP assigns the paraphrase a rank of 10 out of 23. Since the bilingual pivoting method was trained with Europarl data, which is dominated by British english, BiP fails to acknowledge the American spelling of the same word. On the other hand, distributional similarity feature vectors were extracted from the n-gram corpus with different variations of english, hence this information was constructively informative for paraphrase ranking. This property can be exploited for adaptation of specific domain of paraphrases selection.


\begin{table*}
\begin{center}
\begin{tabular}{lcccccc}%{|l|l|l|}
\hline\hline 
&& \multicolumn{4}{c} {\bf \footnotesize Ranking} \\
% example LSH >> BiP
\bf \scriptsize Phrase pair &\bf \scriptsize Size$_{pool}$ & \bf \scriptsize SentID & \bf \scriptsize Meaning & \bf \scriptsize Grammar &\bf \scriptsize BiP & \bf \scriptsize BiP-MonoDS \\ \hline
{\scriptsize \emph{significantly affected, known}} & {\scriptsize 20} & {\scriptsize 10321} & {\scriptsize 19} & {\scriptsize 18.5} & {\scriptsize 1} & {\scriptsize 17} \\
{\scriptsize \emph{considerable changes, caused quite}} & {\scriptsize 23} & {\scriptsize 1069038} & {\scriptsize 23} & {\scriptsize 23} & {\scriptsize 2.5} & {\scriptsize 23} \\
{\scriptsize \emph{always declared, always been}} & {\scriptsize 20} & {\scriptsize 377087} & {\scriptsize 20} & {\scriptsize 20} & {\scriptsize 2} & {\scriptsize 13} \\
%{\scriptsize urgently adopt, take swift} & {\scriptsize 10} & {\scriptsize 1} & {\scriptsize 2.5} & {\scriptsize 5.5} & {\scriptsize 1} \\
{\scriptsize \emph{hauled, delivered}} & {\scriptsize 23} & {\scriptsize 344042} & {\scriptsize 7} & {\scriptsize 5.5} & {\scriptsize 21.5} & {\scriptsize 5.0} \\
{\scriptsize \emph{fiscal burden, taxes}} & {\scriptsize 18} & {\scriptsize 918627} & {\scriptsize 13.5} & {\scriptsize 18} & {\scriptsize 6} & {\scriptsize 16} \\
{\scriptsize \emph{fiscal burden, taxes}} & {\scriptsize 18} & {\scriptsize 272831} & {\scriptsize 2} & {\scriptsize 8} & {\scriptsize 6} & {\scriptsize 16} \\
{\scriptsize \emph{of the size, the size of the}} & {\scriptsize 19} & {\scriptsize 186649} & {\scriptsize 11} & {\scriptsize 17} & {\scriptsize 6} & {\scriptsize 15} \\
{\scriptsize \emph{legalise, legalize}} & {\scriptsize 23} & {\scriptsize 1104188} & {\scriptsize 1} & {\scriptsize 1} & {\scriptsize 10} & {\scriptsize 1} \\
\hline
% example BiP >> LSH
{\scriptsize \emph{to deal properly with, address}} & {\scriptsize 35} & {\scriptsize 1156253} & {\scriptsize 4.5} & {\scriptsize 5.5} & {\scriptsize 4} & {\scriptsize 29.5} \\
{\scriptsize \emph{you have just stated, you have just suggested}} & {\scriptsize 31} & {\scriptsize 129614} & {\scriptsize 13.5} & {\scriptsize 8.5} & {\scriptsize 4} & {\scriptsize 30} \\
{\scriptsize \emph{attackers, forwards on}} & {\scriptsize 34} & {\scriptsize 526677} & {\scriptsize 7.5} & {\scriptsize 6} & {\scriptsize 1} & {\scriptsize 33} \\
%{\scriptsize \emph{}} & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } \\
\hline
\end{tabular}
\end{center}
\caption{Examples of phrase pair rankings by different re-ranking methods and human judgments in terms of meaning and grammar. Higher rank (smaller numbers) corresponds to more favorable paraphrases by the associated metric. Sentence ID is labeled as SentID}
\label{table11}
\end{table*}

 
 
%@@ examples of hiero better than lsh @@ 

\mnote{Additional of sources of error from LSH} %%%
While the monolingual distributional similarity shows promise as a paraphrase ranking method, there are a number of additional drawbacks associated with the implementation through LSH. The process of obtaining counts from the n-gram corpus to construct the distributional feature vector requires traversing through the entire collection of N-grams, which takes a substantial amount of time. A revision of the algorithm to allow parallel processing can possibly alleviate such problem. Another issue is the tradeoff between the size of LSH signature vector and the consistency of approximated phrasal cosine distance over multiple repetitions of LSH extraction. While compactness of LSH features in terms of the the number of bits for each feature vector is desirable for computational speed and storage, it sacrifices the accuracy of the phrasal distributional similarity due the the fact that a smaller vector size translates to a greater dependency of the feature vector on the random seeds in the random projection. 

\mnote{example of sparsity problem} %%%
Moreover, the method is currently limited to phrases with up to 4 contiguous words that are present in the N-gram corpus for LSH feature vector extraction. Since cosine similarity is a function of the angle between 2 vectors irrespective of the vector magnitudes, thresholding on low occurrences of higher n-grams in the corpus construction causes larger n-grams to suffer from feature sparsity and be susceptible to noise. A few examples from the experiment demonstrate such scenario. For a phrase \emph{to deal properly with}, a paraphrase candidate \emph{address} receives rankings of 4.5, 5.5 and 4 out of 35 for meaning, grammar and BiP, respectively, it is ranked 29.5 by BiP-MonoDS. The two phrases are expected to have similar neighboring context in regular english usage, but it might be misrepresented by the LSH feature vector due to the lack of occurrences of the 4-gram in the corpus.

\mnote{example of sparsity problem} %%%
Another example of how data sparsity affects LSH feature vectors is the phrase \emph{you have just stated}. An acceptable paraphrase \emph{you have just suggested} was ranked 13.5, 8.5 and 6.5 out of a total of 31 candidates by meaning, grammar and BiP, respectively, but MonoDS only ranks it at 30. The cosine similarity between the phrases are 0.05, which is very low. However, the only tokens that differentiate the 4-gram phrases, i.e. \{\emph{stated},\emph{suggested}\}, have a similarity score of 0.91. This suggests that even though the additional words in the phrase don't alter the meaning significantly, the feature vectors are misrepresented due to the sparsity of the 4-gram. This also demonstrates the weakness the current implementation of distributional similarity that context within a phrase is not considered for larger n-grams.



{\bf Effects of human judgment quality on gold standard}
%@@ human judgment isn't entirely correct, depending on turker experience with task, with english; context of sentences, length, etc @@
Despite the ease of setup and the economical benefits, subjective evaluation using Mechanical Turk are susceptible to multiple sources of error, causing substantial amount of noise in the collected data. First of all, turker's proficiency in English in terms of either age or language nativeness, would affect how the contextual clues are interpreted, which consequently influence the judgment of the paraphrases. Moreover, the experience in working on HITs and the consistency among, as well as within, turkers would also have an influence in the result quality. 

An example of noisy human judgment is one of the paraphrases generated for the phrase \emph{attackers}. Paraphrase candidate \emph{forwards on} was ranked 7\.5, 6, and 1 out of 34 candidates for meaning, grammar and bilingual-pivoting paraphrase score, respectively, whereas monolingual-based method ranks it at 33. This paraphrase is apparently incorrect but was likely to be generated from misalignment in grammar extraction stage. The actual human scores shows that, with respect to a full score of 5, "forwards on" received 2 and 4 for meaning and 4 and 5 for grammar. These scores do not correlate to the actual paraphrase quality and demonstrates one of the potential noises by human in the data for that influence quality of paraphrase gold standard.


{\bf Why is MonoDS alone insufficient?}

Despite of the better grammatical correlation between the context-based first order distributional similarity and human judgment, this monolingual method alone is insufficient to produce a reasonable ranked list of paraphrases. In addition to the limitation of monolingual distribution similarity such as data vector sparsity, there are other drawbacks when paraphrase candidates are not pre-selected by the bilingual pivoting method. Without a paraphrase filtering scheme, distributional similarity theoretically can be used to generate a list of paraphrases with decreasing similarity score from DS feature vectors of all phrases in the vocabulary, which can be very large. The size of candidate list can be limited based on any desired score cutoff. However, resulting candidates would only be based on contextual similarity that only enforces grammaticality, and as such, no direct restriction on the semantic of phrase is imposed. As a result, the inability of distributional similarity methods to handle cousin terms or antonym is often observed. 

An example in Table \ref{table6} compare the lists of top 10 re-ranked paraphrase generated according to monolingual distributional similarity alone and by bilingual pivoting method. Although monolingual paraphrase extraction method alone produces some reasonable paraphrase such as \emph{somewhat reluctant}, \emph{disinclined}, and \emph{less willing}, the top ranked elements include \emph{willing} and \emph{eager}, which are the antonym of \emph{reluctant}. This exemplifies the ability of monolingual method to capture only grammaticality in paraphrases based on the neighboring content, yet fail to distinguish between antonyms and synonyms. On the other hand, such candidates never gets generated in the pivoting stage by the bilingual pivot method since antonyms unlikely share the same foreign translations. This example illustrates the reason monolingual distributional similarity alone is inadequate for re-ranked paraphrase generation and that bilingual- and monolingual-based techniques provide orthogonal information for paraphrase re-ranking. 

\begin{table}%[t!]
\begin{center}
\begin{tabular}{lll}%{|l|l|l|}
\hline\hline 
\multicolumn{3}{c} {\bf \scriptsize \emph{reluctant}}\\ \hline
\multicolumn{1}{c}{\bf \scriptsize MonoDS-alone} & \multicolumn{1}{c} {\bf \scriptsize BiP} \\ \hline
{\scriptsize \emph{willing} (0.992)} & {\scriptsize \emph{not} (0.558)} & {\scriptsize } \\
{\scriptsize \emph{loath} (0.983)} & {\scriptsize \emph{unwilling} (0.041)} & {\scriptsize } \\
{\scriptsize \emph{eager} (0.98)}& {\scriptsize \emph{reluctance} (0.031)}& {\scriptsize } \\
{\scriptsize \emph{somewhat reluctant} (0.98)} & {\scriptsize \emph{reticent} (0.025)} \\
{\scriptsize \emph{unable} (0.976)} &  {\scriptsize \emph{hesitant} (0.016)} & {\scriptsize } \\
{\scriptsize \emph{denied access} (0.976)}&  {\scriptsize \emph{reticent about} (0.014)} & {\scriptsize } \\
{\scriptsize \emph{disinclined} (0.976)} &  {\scriptsize \emph{reservations} (0.011)} & {\scriptsize } \\
{\scriptsize \emph{very unwilling} (0.974)}&  {\scriptsize \emph{reticence} (0.010)} & {\scriptsize } \\
{\scriptsize \emph{conducive} (0.973)}&  {\scriptsize \emph{hesitate} (0.009)} & {\scriptsize } \\
{\scriptsize \emph{linked} (0.973)}&  {\scriptsize \emph{are reluctant} (0.009)} & {\scriptsize } \\
\hline
\end{tabular}
\end{center}
\caption{Top 10 re-ranked paraphrase candidates for the phrase \emph{reluctant} according to monolingual distributional similarity (MonoDS) alone and bilingual pivoting paraphrase (BiP) method. The corresponding scores are indicated in brackets}
\label{table6} 
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Work}
In this paper, we have presented a novel paraphrase ranking metric that assigns confidence score to paraphrase candidates according to their monolingual distributional similarity to the original phrase. While bilingual pivoting-based paraphrase models provides wide coverage of paraphrase candidates and syntactic constraints on the model confines the structural match, additional contextual similarity information provided by monolingual semantic statistics increases the accuracy of paraphrase ranking within the target language. Reduction of storage and speed for distributional distributional features was achieved by LSH approximation of the feature vectors. Through the experimental study carried out on Mechanical Turk, it was shown that monolingual distributional score correlates strongly with human assessment of paraphrases in terms of grammaticality, yet have minimal effects on meaning preservation of paraphrases.

While we speculated that MonoDS would improve both meaning and grammar scoring for paraphrases based on the fact that contextual similarity entails information in those dimensions, we found in the results that only grammaticality was benefited from the monolingual approach. This is likely due to the choice of contextual features, which in this case is only single neighboring word that carry only local information. A consideration for future work to enhance paraphrasal meaning preservation would be to explore other feature sets, such as syntactic dependency parsing as implemented by \newcite{LinACL97}, mutual information between co-occurences of phrases with words similar to the work of \newcite{ChurchHanks91}, and increasing number of neighboring words in feature extraction.

A main direction of future work is to take full advantage of the complementary knowledge of paraphrase selection in both bilingual and monolingual ranking schemes by combining the corresponding confidence measures along with other features such as n-gram length, language model scores, etc.. One approach would be to perform minimum error rate training similar to \newcite{ZhaoEtAlACL08} in which linear weights of a feature function for a set of paraphrases candidate are trained iteratively to minimize the phrasal-substitution-based error rate. Instead of phrasal substitution in Zhao's method, quantitative measure of correlation with human judgment can be used as the objective function to be optimized during training. Other techniques such as SVM-rank \cite{Joachims02} should also be investigated for aggregating results from multiple ranked lists. 

%The translation score computed with syntactically constrained bilingual paraphrase model implicitly incorporates context dependency for paraphrases through parsing, whereas monolingual distributional similarity inherently lacks such information. One possible modification to the distributional similarity score would be to include the neighboring context in the LSH signature extraction. For example, the word immediately preceding the original phrase in a sentence can be used as the ``right context" concatenated to right-most 3-gram, or less, of the candidate paraphrase, of which a LSH signature can be computed. Similar procedure on the word following the phrase in the sentence would produce a ``left-context" LSH signature. These additional context-dependent features will likely improve the cosine similarity paraphrase ranking.

% re-write the following paragraph: %%%%%%%%%%%%%%%%%%%%%% ================== < here
Traditional methods for computing distributional similarity scores such as the induction process utilized by \newcite{PascaDienes05}, requires substantial computational storage for collecting contextual counts for each phrase in a large collection as well as the amount of time for computing the quantitative measure of paraphrases. As a result, scalability of these methods hinders paraphrase extraction on large data sets. In our study, monolingual distributional similarity is implemented via Locality Sensitive Hashing, which represents contextual features signatures in small dimensions allowing linear time computation of approximate cosine distance, and can update signature in an online fashion \cite{Charikar02,VanDurmeLallACL10}. This encourages future effort of extending the proposed method to very large sets of candidate paraphrases, as well as the establishing a large database of paraphrases and the corresponding distributional similarity signatures.

Other future directions include examining the effect on paraphrases scores from an increased number of pivoting languages in the bilingual paraphrase model, eliminating the limitations imposed by the web-scale n-gram corpus on both the maximum length of phrase tokens and the sparsity of features for higher n-grams, training models with domain-specific corpora to extract distributional similarity signatures tailored for certain applications, and explore the possibility of augmenting the paraphrase extraction procedure to include monolingual features in order to alleviate the problems of misalignment.


%@@ briefly mention applying LSH and tomb counter to reduce paraphrase error due to misalignment ?@@

%@@ combination of difference score through minimum error rate training; should combine non-syntactically constrained model with LSH because hiero style provides larger coverage of candidate paraphrases and LSH can increase confidence in the ones that are more likely to be a good paraphrase, whereas syn-contrained model already throws out large number of candidates @@
%@@ the success from pilot study encourages to move from only small amount of test phrases to a large scale evaluation on mechanical turk; maybe even evaluate effect (on coverage, performance, etc) the number of pivoting languages, which will potentially result in larger number of paraphrase candidates per phrase @@
%@@ Synt-constrainted paraphrasing method by construction incorporate context dependency, whereas the information is absent in the monolingual counterpart, so natural next step would be to include context by taking into account the neighboring words of the phrases; hence would introduce 2 additional context-dependent scores into the larger scale of mTurk evaluation @@
%@@feature sparsity issue due to thresholding in google ngram@@



% ccb nikesh: position indep occurence

\bibliographystyle{acl}
\bibliography{references}

\end{document}


%%% table template

\begin{table}%[t!]
\begin{center}
\begin{tabular}{rcc}%{|l|l|l|}
\hline\hline \bf \footnotesize X & \bf \footnotesize X & \bf \footnotesize X \\ \hline
{\scriptsize } & {\scriptsize } & {\scriptsize } \\
{\scriptsize } & {\scriptsize } & {\scriptsize } \\
{\scriptsize } & {\scriptsize }& {\scriptsize } \\
{\scriptsize } & {\scriptsize } & {\scriptsize } \\
\hline 
{\scriptsize } &  {\scriptsize } & {\scriptsize } \\
{\scriptsize }&  {\scriptsize } & {\scriptsize } \\
{\scriptsize } &  {\scriptsize } & {\scriptsize } \\
{\scriptsize }&  {\scriptsize } & {\scriptsize } \\
\hline
\end{tabular}
\end{center}
\caption{\label{tableX} XX}
\end{table}


%%%%%%%%%%%%%%%% TABLE for evaluation w.r.t. Ngram %%%%%%%%%%%%%%%%%%
\begin{table*}%[t!]
\begin{center}
\begin{tabular}{rcccccccc}%{|l|l|l|}
\hline \hline & \multicolumn{2}{c} {N = 1} &  \multicolumn{2}{c}{N = 2} &  \multicolumn{2}{c}{N = 3} &  \multicolumn{2}{c}{N = 4} \\
\bf \scriptsize Re-ranking Method & \bf \scriptsize M & \bf \scriptsize G  & \bf \scriptsize M & \bf \scriptsize G  & \bf \scriptsize M & \bf \scriptsize G  & \bf \scriptsize M & \bf \scriptsize G  \\ \hline
{\scriptsize Hiero-Hiero} & {\scriptsize 0.18 (120)} & {\scriptsize -0.06 (120)}  & {\scriptsize 0.09 (125)} & {\scriptsize -0.03 (125)}  & {\scriptsize 0.15 (120)} & {\scriptsize 0.15 (117)}  & {\scriptsize 0.14 (110)} & {\scriptsize 0.13 (109)}  \\
{\scriptsize Hiero-LSH} & {\scriptsize 0.03 (125)} & {\scriptsize 0.23 (125)}   & {\scriptsize 0.07 (125)} & {\scriptsize 0.17 (125)}  & {\scriptsize 0.13 (124)} & {\scriptsize 0.29 (121)}  & {\scriptsize 0.33 (119)} & {\scriptsize 0.28 (119)}  \\
{\scriptsize SAMT-SAMT}& {\scriptsize 0.20 (99)}& {\scriptsize 0.00 (97)}  & {\scriptsize 0.26 (74)} & {\scriptsize 0.01 (75)}  & {\scriptsize 0.28 (73)} & {\scriptsize 0.26 (68)}  & {\scriptsize -0.06 (54)} & {\scriptsize 0.08 (52)}  \\
{\scriptsize SAMT-LSH} & {\scriptsize 0.13 (104)} & {\scriptsize 0.21 (102)}  & {\scriptsize 0.17 (84)} & {\scriptsize 0.23 (85)}  & {\scriptsize 0.19 (79)} & {\scriptsize 0.22 (74)}  & {\scriptsize 0.13 (59)} & {\scriptsize 0.21 (57)}  \\ 

%{\scriptsize Hiero-Hiero} & {\scriptsize 0.12} & {\scriptsize 0.03} \\
%{\scriptsize Hiero-LSH} & {\scriptsize 0.12} & {\scriptsize \bf 0.23} \\
%{\scriptsize SAMT-SAMT}& {\scriptsize \bf 0.16}& {\scriptsize 0.06} \\
%{\scriptsize SAMT-LSH} & {\scriptsize 0.13} & {\scriptsize 0.20} \\ 
\hline
\end{tabular}
\end{center}
\caption{\label{tableX} {\bf wont be included in ppr} (M = Meaning, G = Grammar,  = Support) Kendall Tau's rank coefficients for correlation of human judgment, collected from Mechanical Turk experiments, in terms of paraphrase meaning and grammaticality with Hiero-based, SAMT-based, and LSH-based translation scores. Numbers with bolded face are the maximum within that column}
\end{table*}
% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauNgram_all_sorted: all Kendal Tau scores
% cntNgram_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau



%%%%%%%%%%%%%%% table for pphrase size analysis, at LEAST size N %%%%%%%%%%%%%%%

\begin{table*}%[t!]
\begin{center}
\begin{tabular}{rccccccccc}%{|l|l|l|}
\hline \hline \bf \scriptsize Re-ranking & \multicolumn{3}{c} {@3} &  \multicolumn{3}{c}{@6} &  \multicolumn{3}{c}{@10} \\
\bf \scriptsize Method & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S \\ \hline
{\scriptsize Hiero-Hiero} & {\scriptsize 0.12} & {\scriptsize 0.03} & {\scriptsize } & {\scriptsize 0.14} & {\scriptsize 0.01} & {\scriptsize } & {\scriptsize 0.14} & {\scriptsize -0.01} & {\scriptsize } \\
{\scriptsize Hiero-LSH} & {\scriptsize 0.13} & {\scriptsize 0.24} & {\scriptsize } & {\scriptsize 0.11} & {\scriptsize 0.26} & {\scriptsize } & {\scriptsize 0.10} & {\scriptsize 0.23} & {\scriptsize } \\
{\scriptsize SAMT-SAMT} & {\scriptsize 0.17} & {\scriptsize 0.08} & {\scriptsize } & {\scriptsize 0.20} & {\scriptsize 0.08} & {\scriptsize } & {\scriptsize 0.21} & {\scriptsize 0.09} & {\scriptsize } \\
{\scriptsize SAMT-LSH} & {\scriptsize 0.17} & {\scriptsize 0.22} & {\scriptsize } & {\scriptsize 0.20} & {\scriptsize 0.23} & {\scriptsize } & {\scriptsize 0.19} & {\scriptsize 0.22} & {\scriptsize } \\
\hline
\end{tabular}
\end{center}
\caption{\label{tableX} {\bf wont be included in ppr} Kendall Tau's rank coefficients for correlation between human judgment and each re-ranking method as a function of the minimum size of paraphrase candidate pool, where meaning, grammar and support are represented as M, G and S, respectively}
\end{table*}

% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauPPsize_all_sorted: all Kendal Tau scores
% cntPPsize_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau



%%%%%%%%%%%%%%%%% table for pphrase size analysis, at MOST size N %%%%%%%%%%%%%%%%%

\begin{table*}%[t!]
\begin{center}
\begin{tabular}{rcccccccc}%{|l|l|l|}
\hline \hline 
%\bf \scriptsize Re-ranking & \multicolumn{3}{c} {@3} &  \multicolumn{3}{c}{@6} &  \multicolumn{3}{c}{@10} &  \multicolumn{3}{c}{@15} &  \multicolumn{3}{c}{@20} &  \multicolumn{3}{c}{@30} \\
 & \multicolumn{2}{c} {\scriptsize BiP} &  \multicolumn{2}{c}{\scriptsize BiP-MonoDS} &  \multicolumn{2}{c}{\scriptsize SyntBiP} &  \multicolumn{2}{c}{\scriptsize SyntBip-MonoDS} \\
\bf \scriptsize $\leq$ N$_{pool size}$ & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G \\ \hline
{\scriptsize 3} & {\scriptsize 0.24 (36)} & {\scriptsize 0.30 (33)} & {\scriptsize 0.30 (49)} & {\scriptsize 0.21 (47)} & {\scriptsize 1.0 (5)} & {\scriptsize -0.33 (3)}  & {\scriptsize -1.0 (5)} & {\scriptsize 0.33 (3)} \\
{\scriptsize 6} & {\scriptsize 0.16 (90)} & {\scriptsize 0.27 (86)} & {\scriptsize 0.26 (108)} & {\scriptsize 0.25 (105)} & {\scriptsize 0.03 (26)} & {\scriptsize 0.10 (19)} & {\scriptsize -0.34 (26)} & {\scriptsize -0.09 (19)} \\
{\scriptsize 10} & {\scriptsize 0.16 (150)} & {\scriptsize 0.22 (146)} & {\scriptsize 0.24 (168)} & {\scriptsize 0.27 (165)} & {\scriptsize 0.10 (50)} & {\scriptsize 0.10 (43)} & {\scriptsize -0.04 (50)} & {\scriptsize 0.30 (43)} \\
{\scriptsize 15} & {\scriptsize 0.13 (195)} & {\scriptsize 0.18 (191)} & {\scriptsize 0.21(213)} & {\scriptsize 0.28 (210)} & {\scriptsize 0.08 (75)} & {\scriptsize 0.12 (67)} & {\scriptsize 0.01 (83)} & {\scriptsize 0.25 (74)} \\
{\scriptsize 20} & {\scriptsize 0.12 (280)} & {\scriptsize 0.12 (276)} & {\scriptsize 0.18 (298)} & {\scriptsize 0.26 (295)} & {\scriptsize 0.10 (110)} & {\scriptsize 0.10 (102)} & {\scriptsize 0.17 (131)} & {\scriptsize 0.24 (123)} \\
{\scriptsize 30} & {\scriptsize 0.13 (375)} & {\scriptsize 0.07 (371)} & {\scriptsize 0.16 (393)} & {\scriptsize 0.25 (390)} & {\scriptsize 0.21 (200)} & {\scriptsize 0.10 (192)} & {\scriptsize 0.17 (226)} & {\scriptsize 0.23 (218)} \\

\hline
\end{tabular}
\end{center}
\caption{Kendall Tau's rank coefficients for correlation between human judgment and each re-ranking method as a function of the maximum size of paraphrase candidate pool, where the support is indicated in the bracket; meaning and grammar are represented as M and G, respectively}
\label{table7} 
\end{table*}
% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauPPsize_all_sorted: all Kendal Tau scores
% cntPPsize_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau


%%%%%%%%% table for LSH cutoff analysis (replaced by table of the binning of LSH in the ppr)  %%%%%%%%%%%%%
\begin{table}%[t!]
\begin{center}
\begin{tabular}{rcccc}%{|l|l|l|}
\hline \hline
\bf \scriptsize LSH cutoff & \bf \scriptsize Meaning & \bf \scriptsize Grammar & \bf \scriptsize Support \\ \hline
{\scriptsize $\geq$ 0.9} & {\scriptsize 0.19} & {\scriptsize 0.18} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.8} & {\scriptsize 0.24} & {\scriptsize 0.14} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.7} & {\scriptsize 0.15} & {\scriptsize 0.16} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.6} & {\scriptsize 0.10} & {\scriptsize 0.18} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.5} & {\scriptsize 0.13} & {\scriptsize 0.15} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.4} & {\scriptsize 0.12 } & {\scriptsize 0.16} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.3} & {\scriptsize 0.11} & {\scriptsize 0.16} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.2} & {\scriptsize 0.13} & {\scriptsize 0.19} & {\scriptsize }  \\
{\scriptsize $\geq$ 0.1} & {\scriptsize 0.13} & {\scriptsize 0.21} & {\scriptsize }  \\
\hline
\end{tabular}
\end{center}
\caption{Kendall Tau's rank coefficients for correlation between human judgment and LSH score for both meaning and grammar. LSH cutoff is defined as the LSH score above which elements are included in the rank list for calculating Kendall Tau coefficients}
\label{table8}
\end{table}

% variables from which values are taken from in eval_paraphrase_judgment_hit_Apr2011.py
% kTauLSHCutoff_all_sorted: all Kendal Tau scores
% cntLSHCutoff_all: all counts of sentID (i.e. phrase-sentence pair) used to calculate a particular kTau




%\begin{table}%[t!]
%\begin{center}
%\begin{tabular}{ccc}%{|l|l|l|}
%\hline\hline \bf \footnotesize X & \bf \footnotesize X & \bf \footnotesize X \\ \hline
%{\scriptsize } & {\scriptsize } & {\scriptsize } \\
%{\scriptsize } & {\scriptsize } & {\scriptsize } \\
%{\scriptsize } & {\scriptsize }& {\scriptsize } \\
%{\scriptsize } & {\scriptsize } & {\scriptsize } \\
%\hline 
%{\scriptsize } &  {\scriptsize } & {\scriptsize } \\
%{\scriptsize }&  {\scriptsize } & {\scriptsize } \\
%{\scriptsize } &  {\scriptsize } & {\scriptsize } \\
%{\scriptsize }&  {\scriptsize } & {\scriptsize } \\
%\hline
%\end{tabular}
%\end{center}
%\caption{XX}
%\label{table5} 
%\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Paraphrase Examples from Urdu-English Corpus}
\label{sect:results_ur_en}
An example shown in Table~\ref{table1} consists of a list of paraphrases generated for the word  {\em unnecessarily} and the corresponding paraphrase scores from each of the 3 confidence metrics. Only the top 5 candidates are shown for the ease of comparison. Out of the top 5 paraphrases, only two from the original bilingual paraphrase extraction are semantically close to actual phrase and none of them are syntactically correct. With the S-C paraphrase model, only the best paraphrase candidate, {\em needlessly}, carries the close enough meaning to {\em unnecessarily}. 

The lack of semantic correspondence in the bilingual methods is likely due to either polysemy in the foreign translation or word alignment mismatch in the bilingual translation. Such problems are not pronounced in the monolingual-based scores. The four paraphrases with the highest LSH-approximated cosine distance are very similar in meaning to the original phrase. Note that cosine distance ranges from -1 to 1 with 1 corresponding to the best match, so the LSH paraphrase candidates in this example are quantitatively close to the true phrase in terms of distributional similarity.

\begin{table}[h]
\begin{center}
\begin{tabular}{ccc}%{|l|l|l|}
\hline\hline \bf \footnotesize BiP & \bf \footnotesize SyntBiP & \bf \footnotesize MonoDS \\ \hline
{\scriptsize necessary (0.118)} & {\scriptsize needlessly (0.024)} & {\scriptsize needlessly (0.93)} \\
{\scriptsize reason (0.084)} & {\scriptsize only (0.012)} & {\scriptsize groundless (0.85)} \\
{\scriptsize unnecessary (0.074)}& {\scriptsize exactly (0.003)}& {\scriptsize unnecessary (0.79)}\\
{\scriptsize same (0.050)} & {\scriptsize just (0.001)} & {\scriptsize useless (0.79)} \\
{\scriptsize useless (0.037)}& {\scriptsize always (0.001)}& {\scriptsize illegally (0.78)}\\
%{\scriptsize necessary (-2.14)} & {\scriptsize needlessly (-3.75)} & {\scriptsize needlessly (0.93)} \\
%{\scriptsize reason (-2.48)} & {\scriptsize only (-4.41)} & {\scriptsize groundless (0.85)} \\
%{\scriptsize unnecessary (-2.60)}& {\scriptsize exactly (-5.80)}& {\scriptsize unnecessary (0.79)}\\
%{\scriptsize same (-2.99)} & {\scriptsize just (-6.74)} & {\scriptsize useless (0.79)} \\
%{\scriptsize useless (-3.30)}& {\scriptsize always (-6.74)}& {\scriptsize illegally (0.78)}\\
\hline
\end{tabular}
\end{center}
\caption{Paraphrases for {\em unnecessarily} according to the original (Hiero), syntactic-constraint-based (SAMT) translation score and the monolingual similarity score(LSH), ranked by corresponding scores in brackets}
\label{table1}
\end{table}

Table~\ref{table2} shows another example of the extracted paraphrases for the phrase {\em huge amount of}. Although monolingual distributional similarity does not explicitly impose syntactic restrictions, the paraphrase {\em in large numbers} in this example was assigned a low score of 0.098 as compared to other paraphrase candidates with correct syntactic type. Its syntactic structure causes its left and right context in the English corpus to be drastically different from that of the original phrase, resulting in a low LSH score. Note that the S-C paraphrase model returns significantly less candidates, which exemplifies the lack of coverage commonly observed in this paraphrase model as mentioned in (Callison-Burch, 2008.) Therefore, it is important to expand the paraphrases for the monolingual scoring by taking the union of candidates from both kinds of bilingual paraphrase model.

\begin{table}[t!]
\begin{center}
\begin{tabular}{ccc}%{|l|l|l|}
\hline\hline 
\bf \small BiP & \bf \small SyntBiP & \bf \small MonoDS \\ \hline

{\scriptsize large number of, 0.33} & {\scriptsize large number of, 0.38} & {\scriptsize large quantity of, 0.98} \\
{\scriptsize in large numbers, 0.11} & {\scriptsize great number of, 0.09} & {\scriptsize large number of, 0.98} \\
{\scriptsize great number of, 0.08}& {\scriptsize vast number of, 0.06}& {\scriptsize great number of, 0.97}\\
{\scriptsize large numbers of, 0.06} & & {\scriptsize vast number of, 0.94} \\
{\scriptsize vast number of, 0.06}& & {\scriptsize in large numbers, 0.10}\\

%{\scriptsize large number of, 0.333} & {\scriptsize large number of, 0.375} & {\scriptsize large quantity of, 0.98} \\
%{\scriptsize in large numbers, 0.111} & {\scriptsize great number of, 0.093} & {\scriptsize large number of, 0.98} \\
%{\scriptsize great number of, 0.084}& {\scriptsize vast number of, 0.063}& {\scriptsize great number of, 0.97}\\
%{\scriptsize large numbers of, 0.056} & & {\scriptsize vast number of, 0.94} \\
%{\scriptsize vast number of, 0.056}& & {\scriptsize in large numbers, 0.10}\\

%{\scriptsize large number of, -1.10} & {\scriptsize large number of, -0.98} & {\scriptsize large quantity of, 0.98} \\
%{\scriptsize in large numbers, -2.20} & {\scriptsize great number of, -2.37} & {\scriptsize large number of, 0.98} \\
%{\scriptsize great number of, -2.48}& {\scriptsize vast number of, -2.77}& {\scriptsize great number of, 0.97}\\
%{\scriptsize large numbers of, -2.89} & & {\scriptsize vast number of, 0.94} \\
%{\scriptsize vast number of, -2.89}& & {\scriptsize in large numbers, 0.10}\\
\hline
\end{tabular}
\end{center}
\caption{Paraphrases for {\em huge amount of} according to the bilingual pivoting (BiP), syntactic-constrainted bilingual pivoting (SyntBiP) translation score and the monolingual similarity score via LSH (MonoDS), ranked by corresponding scores listed next to each paraphrase}
\label{table2}
\end{table}

%@@ discuss adv and disadv of each of the scores; LSH complementary to the shortfall of paraphrases extracted by parallel corpus, e.g. multiple meaning of foreign word would result in paraphrases that isn't correct at all @@

%@@ LSH score: computation duration due to distributional counts collection, tradeoff between storage/LSH signature vector size and consistency/accuracy of approximated cosine distance due to random seeds required for random projection algorithm; currently only supports contiguous phrases and phrases of up-to-4-gram; ALSO only limited to phrases seen in the n-gram corpus; 

%@@first time applied to paraphrase reranking as compared to previous approaches of paraphrase-extraction entirely based on monolingual parallel corpus; issue/relationship with thresholding similarity score; issue of feature dimension sparsity of higher-n-gram due to occurrence count thresholding in google ngram @@

%@@ word alignment issue - inherent in paraphrase methods based on pivoting, regardless of ranking scores @@

%@@@ mention amount of paraphrases extracted from ur-en


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pilot Study Results}
\label{sect:results_pilot}

Table \ref{tbl:table3} shows the Kendall's tau coefficients that quantifies the correlation between paraphrase re-ranking scores and human judgment collected using the Mechanical Turk. The positive values listed indicate that both paraphrase measures agree with human judgment in terms of meaning-preservation (0.28 and 0.19 for monolingual and bilingual, respectively) and grammaticality (0.31 and 0.15.) However, human judgment associates stronger with distributional similarity score with significantly higher coefficient values than bilingual translation score, with a larger difference in the grammaticality category. This implies that statistical semantic information provided through distributional similarity is useful for judging the naturalness of paraphrase perceived by humans and provides additional grammatical information as compared to bilingual pivoting-based re-ranking metrics. This conclusion motivates the next experimental study for exploring the benefits of combining monolingual and multilingual resources in the task of paraphrase extraction.

\begin{table}
\begin{center}
\footnotesize
\begin{tabular}{rcc} 
\hline
\hline
 & {\bf MonoDS} & {\bf BiP}\\
 Meaning &  0.28     &  0.19 \\
 Grammar &  0.31   &  0.15 \\
\end{tabular}
\caption{\small Kendall Tau's rank coefficient, comparing the paraphrase ranking quality of monolingual and bilingual scores, with respect to human judgments, for the pilot study.}
\label{tbl:table3}
\end{center}
\end{table}

\mnote{include table of paraphrase examples for ``study in detail" ?}
%The paraphrase candidates generated and ranked by each of the scores are listed in Table \ref{tbl:pp-candidates}. 

%@@ note: context-aware, take information from Courtney's ppr @@
%@@ setup, evaluation method and purposes, examples, overall results, ..@@

% the following table 
%\begin{table}
%\begin{center}
%\footnotesize
%\begin{tabular}{rcc}
%\hline
%\hline
%{\bf Paraphrase} & {\bf Monlingual} & {\bf Bilingual} \\
% study in detail          &  1.00 &  0.70\\
% scrutinise               &  0.94 &  0.08\\
% carefully examine        &  0.93 &  0.08\\
% keep                     &  0.83 &  0.03\\
% studying more closely    &  0.64 &  0.04\\
% analysing                &  0.61 &  0.06\\
%     study                    &  0.42 &  0.07 \\
%     studied                  &  0.28 &  0.01 \\
%     studied in greater depth &  0.13 &  0.02 \\
%     undertook                &  0.06 &  0.06 \\
%\end{tabular}
%\caption{\small \small Subset of 4-gram-or-less paraphrase candidates for {\em study in detail} with corresponding approximate distributional similarity (Monolingual) and translation model (Bilingual) scores.}
%\label{tbl:pp-candidates}
%\end{center}
%\end{table}





%%%%%%%%%%%%% Average of **mean** of Top K meaning and grammar for each re-ranking score %%%%%%%%%%%%%%%%%%
\begin{table*}%[t!]
\begin{center}
\begin{tabular}{rcccccccccccc}%{|l|l|l|}
\hline \hline & \multicolumn{3}{c} {\scriptsize BiP} &  \multicolumn{3}{c}{\scriptsize BiP-MonoDS} &  \multicolumn{3}{c}{\scriptsize SyntBiP} &  \multicolumn{3}{c}{\scriptsize SyntBip-MonoDS} \\
\bf \scriptsize Top K & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S \\ \hline
{\scriptsize 1} & {\scriptsize 3.62} & {\scriptsize 3.83} & {\scriptsize 500} & {\scriptsize 3.67} & {\scriptsize 4.11} & {\scriptsize 500} & {\scriptsize 3.60} & {\scriptsize 4.04} & {\scriptsize 390} & {\scriptsize 3.60} & {\scriptsize 4.20} & {\scriptsize 390}  \\
{\scriptsize 3} & {\scriptsize 3.50} & {\scriptsize 3.61} & {\scriptsize 465} & {\scriptsize 3.50} & {\scriptsize 3.99} & {\scriptsize 465} & {\scriptsize 3.55} & {\scriptsize 4.01} & {\scriptsize 290} & {\scriptsize 3.42} & {\scriptsize 4.16} & {\scriptsize 290}  \\
{\scriptsize 5} & {\scriptsize 3.44} & {\scriptsize 3.58} & {\scriptsize 425} & {\scriptsize 3.37} & {\scriptsize 3.89} & {\scriptsize 425} & {\scriptsize 3.46} & {\scriptsize 3.99} & {\scriptsize 245} & {\scriptsize 3.37} & {\scriptsize 4.15} & {\scriptsize 245}  \\
{\scriptsize 7} & {\scriptsize 3.35} & {\scriptsize 3.52} & {\scriptsize 385} & {\scriptsize 3.28} & {\scriptsize 3.83} & {\scriptsize 385} & {\scriptsize 3.42} & {\scriptsize 3.95} & {\scriptsize 205} & {\scriptsize 3.32} & {\scriptsize 4.09} & {\scriptsize 205}  \\
{\scriptsize 10} & {\scriptsize 3.29} & {\scriptsize 3.50} & {\scriptsize 360} & {\scriptsize 3.18} & {\scriptsize 3.75} & {\scriptsize 360} & {\scriptsize 3.20} & {\scriptsize 3.83} & {\scriptsize 160} & {\scriptsize 3.14} & {\scriptsize 4.00} & {\scriptsize 160}  \\
{\scriptsize 15} & {\scriptsize 3.25} & {\scriptsize 3.57} & {\scriptsize 305} & {\scriptsize 3.17} & {\scriptsize 3.76} & {\scriptsize 305} & {\scriptsize 3.01} & {\scriptsize 3.79} & {\scriptsize 140} & {\scriptsize 3.00} & {\scriptsize 3.91} & {\scriptsize 140}  \\
{\scriptsize 20} & {\scriptsize 3.16} & {\scriptsize 3.62} & {\scriptsize 210} & {\scriptsize 3.07} & {\scriptsize 3.78} & {\scriptsize 210} & {\scriptsize 2.88} & {\scriptsize 3.74} & {\scriptsize 100} & {\scriptsize 2.86} & {\scriptsize 3.82} & {\scriptsize 100}  \\
%\hline \hline \bf \scriptsize Re-ranking & \multicolumn{3}{c} {K = 1} &  \multicolumn{3}{c}{K = 3} &  \multicolumn{3}{c}{K= 5} &  \multicolumn{3}{c}{K = 7} &  \multicolumn{3}{c}{K = 10} &  \multicolumn{3}{c}{K = 15} &  \multicolumn{3}{c}{K = 20} \\
%\bf \scriptsize Method & \bf \scriptsize M & \bf \scriptsize G  & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize S \\ \hline
%{\scriptsize BiP} & {\scriptsize 3.62} & {\scriptsize 3.83} & {\scriptsize } & {\scriptsize 3.50}  & {\scriptsize 3.61} & {\scriptsize } & {\scriptsize 3.44} & {\scriptsize 3.58} & {\scriptsize } & {\scriptsize 3.35} & {\scriptsize 3.52} & {\scriptsize } & {\scriptsize 3.29} & {\scriptsize 3.50} & {\scriptsize } & {\scriptsize 3.25} & {\scriptsize 3.57} & {\scriptsize }  & {\scriptsize 3.16} & {\scriptsize 3.62} & {\scriptsize } \\
%{\scriptsize BiP-MonoDS}  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  \\
%{\scriptsize SyntBiP} & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  \\
%{\scriptsize SyntBiP-MonoDS} & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize } & {\scriptsize }  \\
\hline
\end{tabular}
\end{center}
\caption{\emph{convert into a graph later}Average of the mean human evaluation score from top K candidates for each re-ranking method (M = Meaning, G = Grammar,  S = Support) }
\label{table11}
\end{table*}

% variable avgTopKmean in code, e.g. avgTopKmean[kTop]['meaning']['hiero']


%%%%%%%%%%%%% Average of **max** of Top K meaning and grammar for each re-ranking score 
% same as table10 but in different arrangements
\begin{table*}%[t!]
\begin{center}
\begin{tabular}{rccccccccc}%{|l|l|l|}
\hline \hline & & \multicolumn{2}{c} {\footnotesize K = 1} &  \multicolumn{2}{c}{\footnotesize K = 3} &  \multicolumn{2}{c}{\footnotesize K= 5} &  \multicolumn{2}{c}{\footnotesize K = 10} \\
\bf \scriptsize Re-ranking Method & \bf \scriptsize S & \bf \scriptsize M & \bf \scriptsize G  & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G & \bf \scriptsize M & \bf \scriptsize G \\ \hline
{\scriptsize BiP} & {\scriptsize 500} & {\scriptsize 3.62 } & {\scriptsize 3.83} & {\scriptsize 4.13} & {\scriptsize 4.22}  & {\scriptsize 4.26} & {\scriptsize 4.38} & {\scriptsize 4.39} & {\scriptsize 4.52}  \\
{\scriptsize BiP-MonoDS} & {\scriptsize 500} & {\scriptsize 3.67} & {\scriptsize 4.11} & {\scriptsize 4.07} & {\scriptsize 4.45}  & {\scriptsize 4.19} & {\scriptsize 4.54} & {\scriptsize 4.30} & {\scriptsize 4.62}  \\
{\scriptsize SyntBiP}& {\scriptsize 335} & {\scriptsize 3.58} & {\scriptsize 4.04} & {\scriptsize 4.13} & {\scriptsize 4.47}  & {\scriptsize 4.20} & {\scriptsize 4.55} & {\scriptsize 4.25} & {\scriptsize 4.63} \\
{\scriptsize SyntBiP-MonoDS} & {\scriptsize 335} & {\scriptsize 3.58} & {\scriptsize 4.23} & {\scriptsize 4.01} & {\scriptsize 4.54}  & {\scriptsize 4.09} & {\scriptsize 4.62} & {\scriptsize 4.23} & {\scriptsize 4.67} \\
\hline
\end{tabular}
\end{center}
\caption{Average of the maximum human evaluation score from top K candidates for each re-ranking method (M = Meaning, G = Grammar,  S = Support) }
\label{table14} 
\end{table*}
% variable avgTopK in code, e.g. avgTopK[kTop]['meaning']['hiero']

